
<ul class="download">
<li><a href="smartthreadpool_2.2.3.zip">Download SmartThreadPool 2.2.3 source, examples, tests, and demos - 651KB</a></li></ul>


<p><img width="600" height="405" src="smartthreadpool.jpg" /></p>

<p>See the <a href="#History">History</a> section at the bottom for changes.</p>

<h2>Basic usage&nbsp;</h2>

<p>This is a Thread Pool; if you got here, you probably know what you need. If you want to understand the features and know how it works, keep reading the sections below. If you just want to use it, here is a quick usage snippet. See <a href="#SimpleExample">examples</a> for advanced usage.</p>

<pre lang="cs">// Create an instance of the Smart Thread Pool
SmartThreadPool smartThreadPool = new SmartThreadPool();

// Queue an action (Fire and forget)
smartThreadPool.QueueWorkItem(System.IO.File.Copy, 
  @&quot;C:\Temp\myfile.bin&quot;, @&quot;C:\Temp\myfile.bak&quot;);

// The action (file copy) will be done in the background by the Thread Pool</pre>

<h2><a name="Introduction">Introduction</a></h2>

<p>Smart Thread Pool is a thread pool written in C#. The implementation was first based on Stephan Toub's thread pool with some extra features, but now, it is far beyond the original. Here is a list of the thread pool features:</p>

<ul>
<li>The number of threads dynamically changes according to the workload on the threads in the pool.&nbsp;</li>

<li>Work items can return a value.</li>

<li>A work item can be cancelled if it hasn't been executed yet.</li>

<li>The caller thread's context is used when the work item is executed (limited).</li>

<li>Usage of minimum number of Win32 event handles, so the handle count of the application won't explode.</li>

<li>The caller can wait for multiple or all the work items to complete.</li>

<li>A work item can have a <code>PostExecute</code> callback, which is called as soon the work item is completed.</li>

<li>The state object that accompanies the work item can be disposed automatically.</li>

<li>Work item exceptions are sent back to the caller.</li>

<li>Work items have priority.</li>

<li>Work items group.</li>

<li>The caller can suspend the start of a thread pool and work items group.</li>

<li>Threads have priority.</li>

<li>Threads have initialization and termination events.</li>

<li>WinCE platform is supported (limited).</li>

<li><code>Action&lt;T&gt;</code> and <code>Func&lt;T&gt;</code> generic methods are supported.</li>

<li><t>Silverlight is supported.</t></li>

<li>Mono is supported.</li>

<li><t>Performance counters (Windows and internal).</t></li>

<li>Work item timeout (passive).</li>
<li>Threads ApartmentState</li>
<li>Threads IsBakcground</li>
<li>Threads name template</li>
<li>Windows Phone is supported (limited)</li>
<li>Threads MaxStackSize</li>

</ul>

<h2>Why do you need a thread pool?</h2>

<blockquote>
<p>&quot;Many applications create threads that spend a great deal of time in the sleeping state, waiting for an event to occur. Other threads might enter a sleeping state only to be awakened periodically to poll for a change or update status information. Thread pooling enables you to use threads more efficiently by providing your application with a pool of worker threads that are managed by the system. One thread monitors the status of several wait operations queued to the thread pool. When a wait operation completes, a worker thread from the thread pool executes the corresponding callback function&quot;.</p>

<p>MSDN, April 2004, ThreadPool Class [C#].</p>
</blockquote>

<h2>Smart Thread Pool features</h2>

<p>When I wrote my application, I discovered that I needed a thread pool with the following features:</p>

<ul>
<li>The thread pool should implement the <code>QueueUserWorkItem()</code> method to comply with the .NET ThreadPool.</li>

<li>The thread pool should be instantiated. (No static methods.) So, the threads in the pool are used only for one purpose.</li>

<li>The number of threads in the pool should be dynamic with lower and upper limits.</li>
</ul>

<p>After I published the Smart Thread Pool here, I found out that more features were required and some features had to change. So, the following is an updated list of the implemented features:</p>

<ol>
<li><a href="#Feature1">The thread pool is instantiable</a>.</li>

<li><a href="#Feature2">The number of threads dynamically changes</a>.</li>

<li><a href="#Feature3">Work items return a value</a>.</li>

<li><a href="#Feature4">The caller can wait for multiple work items to complete</a>.</li>

<li><a href="#Feature5">A work item can be cancelled</a>.</li>

<li><a href="#Feature6">The caller thread's context is used when the work item is executed (limited)</a>.</li>

<li><a href="#Feature7">Usage of minimum number of Win32 event handles, so the handle count of the application won't explode</a>.</li>
</ol>

<p>Because of features 3 and 5, the thread pool no longer complies to the .NET ThreadPool, and so I could add more features.</p>

<p>See the additional features section below for the new features added in this version.</p>

<h2>Additional features added in December 2004</h2>

<ol>
<li value="8"><a href="#Feature8">Every work item can have a PostExecute callback. This is a method that will be called right after the work item execution has been completed</a>.</li>

<li><a href="#Feature9">The user can choose to automatically dispose off the state object that accompanies the work item</a>.</li>

<li><a href="#Feature10">The user can wait for the Smart Thread Pool to become idle</a>.</li>

<li><a href="#Feature11">Exception handling has been changed, so if a work item throws an exception, it is re-thrown at <code>GetResult()</code>, rather than firing an <code>UnhandledException</code> event. Note that <code>PostExecute</code> exceptions are always ignored</a>.</li>
</ol>

<h2>New features added in January 2006</h2>

<ol>
<li value="12"><a href="#Feature12">Work items have priority</a>.</li>

<li><a href="#Feature13">The caller thread's HTTP context can be used when the work item is executed (improves 6)</a>.</li>

<li><a href="#Feature14">Work items group</a>.</li>

<li><a href="#Feature15">The caller can create thread pools and work item groups in suspended state</a>.</li>

<li><a href="#Feature16">Threads have priority</a>.</li>
</ol>

<h2>New features added in May 2008</h2>

<ol>
<li value="17"><a href="#Feature17">Enabled the change of <code>MaxThreads</code>/<code>MinThreads</code>/<code>Concurrency</code> at run time</a>.</li>

<li><a href="#Feature5">Improved the Cancel behavior (see section 5)</a>.</li>

<li><a href="#Feature19">Added callbacks for initialization and termination of threads</a>.</li>

<li><a href="#Feature20">Added support for WinCE (limited)</a>.</li>

<li><a href="#Feature21">Added the <code>IsIdle</code> flag to <code>SmartThreadPool</code> and to <code>IWorkItemsGroup</code></a>.</li>

<li><a href="#Feature3">Added support for <code>Action&lt;T&gt;</code> and <code>Func&lt;T&gt;</code> (strong typed work items) (see section 3)</a>.</li>
</ol>

<h2>New features added in April 2009</h2>

<ol>
<li value="23"><a href="#Feature23">Added support for Silverlight</a>.</li>

<li><a href="#Feature24">Added support for Mono</a>.</li>

<li><a href="#Feature25">Added internal performance counters (for Windows CE, Silverlight, and Mono)</a>.</li>

<li><a href="#Feature26">Added new methods: <code>Join</code>, <code>Choice</code>, and <code>Pipe</code></a>.</li>
</ol>

<h2>New features added in December 2009</h2>

<ol>
<li value="27"><a href="#Feature27">Added work item timeout (passive)</a>.</li>
</ol>
<h2>
    New features added in August 2012</h2>
<ol>
    <li value="28"><a href="#Feature28">Enabled to set threads IsBackground.</a></li>
    <li value="29"><a href="#Feature29">Enabled to set threads ApartmentState.
    </a></li>
<li value="30"><a href="#Feature30">Added support fore Windows Phone (limited).</a></li>
<li value="31"><a href="#Feature30"></a><a href="#Feature31">Enabled to set threads MaxStackSize.</a></li>
</ol>
<p>


</p><h2>What about the .NET ThreadPool?&nbsp;</h2>

<p>The Windows system provides one .NET ThreadPool for each process. The .NET ThreadPool can contain up to 25 (by default) threads per processor. It is also stated that the operations in the .NET ThreadPool should be quick to avoid suspension of the work of others who use the .NET ThreadPool. Note that several AppDomains in the same process share the same .NET ThreadPool. If you want a thread to work for a long period of time, then the .NET ThreadPool is not a good choice for you (unless you know what you are doing). Note that each asynchronous method call from the .NET Framework that begins with &quot;Begin…&quot; (e.g., <code>BeginInvoke</code>, <code>BeginSend</code>, <code>BeginReceive</code>, etc.) uses the .NET ThreadPool to run its callback. Also note that the .NET ThreadPool doesn't support calls to COM with single threaded apartment (STA), since the ThreadPool threads are MTA by design.</p>

<p>This thread pool doesn't comply with the requirements 1, 5, 6, 8, 9, 10, 12-25.</p>

<p>Note that the requirements 3 and 4 are implemented in .NET ThreadPool with delegates.</p>

<h2>What about Stephen Toub's thread pool?</h2>

<p>Toub's thread pool is a better choice than the .NET ThreadPool, since a thread from his pool can be used for a longer period of time without affecting asynchronous method calls. Toub's thread pool uses static methods; hence, you cannot instantiate more than one thread pool. However, this limitation applies per AppDomain rather than the whole process. The main disadvantage of Toub's thread pool over the .NET TheradPool is that Toub creates all the threads in the pool at the initialization point, while the .NET ThreadPool creates threads on the fly.</p>

<p>This thread pool doesn't comply with the requirements 1, 2, 3, 4, 5, 6, 8-25.</p>

<h2>The Smart Thread Pool design and features</h2>

<p>As I mentioned before, the Smart Thread Pool is based on Toub's thread pool implementation. However, since I have expanded its features, the code is no longer similar to the original one.</p>

<p>Features implementation:</p>

<ol>
<li><a name="Feature1"><strong>The thread pool is instantiable</strong></a>.</li>

<p>The reason I need an instantiable thread pool is because I have different needs. I have work items that take a long time to execute, and I have work items that take a very short time to execute. Executing the same type of work items on the same thread pool may cause some serious performance or response problems.</p>

<p>To implement this feature, I just copied Toub's implementation and removed the <code lang="cs">static</code> keyword from the methods. That's the easy part of it.</p>

<li><a name="Feature2"><strong>The number of threads dynamically changes</strong></a>.</li>

<p>The number of threads dynamically changes according to the workload on the threads in the pool, with lower and upper constraints for the number of threads in the pool. This feature is needed so we won't have redundant threads in the application.</p>

<p>This feature is a real issue, and is the core of the Smart Thread Pool. How do you know when to add a new thread and when to remove it?</p>

<p>I decided to add a new thread every time a new work item is queued and all the threads in the pool are busy. The formula for adding a new thread can be summarized to:</p>

<pre lang="text">_currentWorkItemsCount &gt; WorkerThreads</pre>

<p>where <code>WorkerThreads</code> is the current number of threads in the pool, <code>InUseThreads</code> is the number of threads in the pool that are currently working on a work item, and <code>WaitingCallbacks</code> is the number of waiting work items. (Thanks to <strong>jrshute</strong> for the comment.)</p>

<p>The <code>SmartThreadPool.Enqueue()</code> method looks like this:</p>

<pre lang="cs">private void Enqueue(WorkItem workItem) 
{ 
    // Make sure the workItem is not null 
    Debug.Assert(null != workItem); 

    // Enqueue the work item
    _workItemsQueue.EnqueueWorkItem(workItem); 

    // If all the threads are busy then try 
    // to create a new one 
    if (_currentWorkItemsCount &gt; _workerThreads.Count) 
    { 
        StartThreads(1); 
    } 
}</pre>

<p>When the number of threads reaches the upper limit, no more threads are created.</p>

<p>I decided to remove a thread from the pool when it is idle (i.e., the thread doesn't work on any work item) for a specific period of time. Each time a thread waits for a work item on the work item's queue, it also waits for a timeout. If the waiting exceeds the timeout, the thread should leave the pool, meaning the thread should quit if it is idle. It sounds like a simple solution, but what about the following scenario: assume that the lower limit of threads is 0 and the upper limit is 100. The idle timeout is 60 seconds. Currently, the thread pool contains 60 threads, and each second, a new work item arrives, and it takes a thread one second to handle a work item. This means that, each minute, 60 work items arrive and are handled by 60 threads in the pool. As a result, no thread exits, since no thread is idle for a full 60 seconds, although 1 or 2 threads are enough to do all the work.</p>

<p>In order to solve the problem of this scenario, you have to calculate how much time each thread worked, and once in a while, exit the threads that don't work for enough time in the timeout interval. This means, the thread pool has to use a timer (use the .NET ThreadPool) or a manager thread to handle the thread pool. To me, it seems an overhead to use a special thread to handle a thread pool.</p>

<p>This led me to the idea that the thread pool mechanism should starve the threads in order to let them quit. So, how do you starve the threads?</p>

<p>All the threads in the pool are waiting on the same work items queue. The work items queue manages two queues: one for the work items and one for the waiters (the threads in the pool). Since the trivial work items queue works, the first arrived waiter for a work item gets it first (queue), and so you cannot starve the threads.</p>

<p>Have a look at the following scenario:</p>

<p>The thread pool contains four threads. Let's name them A, B, C, and D. Every second, a new work item arrives, and it takes less than one second and a half to handle each work item:</p>

<table width="550" class="ArticleTable">
<thead>
<tr>
<td>
<p align="center">Work item arrival time (sec)</p>
</td>

<td>
<p align="center">Work item work duration (sec)</p>
</td>

<td>
<p align="center">Threads queue state</p>
</td>

<td>
<p align="center">The thread that will execute the arrived work item</p>
</td>
</tr>
</thead>

<tbody>
<tr>
<td align="center">
<p align="center">00:00:00</p>
</td>

<td align="center">
<p align="center">1.5</p>
</td>

<td width="113" align="center">
<p align="center">A, B, C, D</p>
</td>

<td align="center">
<p align="center">A</p>
</td>
</tr>

<tr>
<td align="center">
<p align="center">00:00:01</p>
</td>

<td align="center">
<p align="center">1.5</p>
</td>

<td width="113" align="center">
<p align="center">B, C, D</p>
</td>

<td align="center">
<p align="center">B</p>
</td>
</tr>

<tr>
<td align="center">
<p align="center">00:00:02</p>
</td>

<td align="center">
<p align="center">1.5</p>
</td>

<td width="113" align="center">
<p align="center">C, D, A</p>
</td>

<td align="center">
<p align="center">C</p>
</td>
</tr>

<tr>
<td align="center">
<p align="center">00:00:03</p>
</td>

<td align="center">
<p align="center">1.5</p>
</td>

<td width="113" align="center">
<p align="center">D, A, B</p>
</td>

<td align="center">
<p align="center">D</p>
</td>
</tr>
</tbody>
</table>

<p>In this scenario, all the four threads are used, although two threads could handle all the work items.</p>

<p>The solution is to implement the waiters queue as a stack. In this implementation, the last arrived waiter for a work item gets it first (stack). This way, a thread that just finished its work on a work item waits as the first waiter in the queue of waiters.</p>

<p>The previous scenario will look like this with the new implementation:</p>

<table width="550" class="ArticleTable">
<thead>
<tr>
<td>
<p align="center">Work item arrival time (sec)</p>
</td>

<td>
<p align="center">Work item work duration (sec)</p>
</td>

<td>
<p align="center">Threads queue state</p>
</td>

<td>
<p align="center">The thread that will execute the arrived work item</p>
</td>
</tr>
</thead>

<tbody>
<tr>
<td align="center">
<p align="center">00:00:00</p>
</td>

<td align="center">
<p align="center">1.5</p>
</td>

<td align="center">
<p align="center">A, B, C, D</p>
</td>

<td align="center">
<p align="center">A</p>
</td>
</tr>

<tr>
<td align="center">
<p align="center">00:00:01</p>
</td>

<td align="center">
<p align="center">1.5</p>
</td>

<td align="center">
<p align="center">B, C, D</p>
</td>

<td align="center">
<p align="center">B</p>
</td>
</tr>

<tr>
<td align="center">
<p align="center">00:00:02</p>
</td>

<td align="center">
<p align="center">1.5</p>
</td>

<td align="center">
<p align="center">A, C, D</p>
</td>

<td align="center">
<p align="center">A</p>
</td>
</tr>

<tr>
<td align="center">
<p align="center">00:00:03</p>
</td>

<td align="center">
<p align="center">1.5</p>
</td>

<td align="center">
<p align="center">B, C, D</p>
</td>

<td align="center">
<p align="center">B</p>
</td>
</tr>
</tbody>
</table>

<p>Threads A and B handle all the work items, since they get back to the front of the waiters queue after they have finished. Threads C and D are starved, and if the same work items are going to arrive for a long time, then threads C and D will have to quit.</p>

<p>The thread pool doesn't implement a load balancing mechanism, since all the threads run on the same machine and take the same CPUs. Note that if you have many threads in the pool, then you will prefer the minimum number of threads to do the job, since each context switch of the threads may result in paging of the threads' stacks. Less working threads means less paging of the threads' stacks.</p>

<p>The work items queue implementation causes threads to starve, and the starved threads quit. This solves the scenario I mentioned earlier without using any extra thread.</p>

<p>The second feature also states that there should be a lower limit to the number of threads in the pool. To implement this feature, every thread that gets a timeout, because it doesn't get any work items, checks whatever it can quit. Smart Thread Pool allows the thread to quit only if the current number of threads is above the lower limit. If the number of threads in the pool is below or equal to the lower limit, then the thread stays alive.</p>

<li lang="cs"><a name="Feature3"><strong>Work items return a value</strong></a> (this feature is enhanced).</li>

<p>This feature is very useful in cases where you want to know the result of a work item.</p>

<p>The .NET ThreadPool supports this feature via delegates. Each time you create a delegate, you get the <code>BeginInvoke()</code> and <code>EndInvoke()</code> methods for free. <code>BeginInvoke()</code> queues the method and its parameters on the .NET ThreadPool, and <code>EndInvoke()</code> returns the result of the method. The delegate class is <code lang="cs">sealed</code>, so I couldn't override the <code>BeginInvoke()</code> and <code>EndInvoke()</code> methods. I took a different approach to implement this.</p>

<p>First, the work item callback delegate can return a value:</p>

<pre lang="cs">public delegate object WorkItemCallback(object state);</pre>

<p>Or in its enhanced form, the callback can be any of the following forms:</p>

<pre lang="cs">public delegate void Action(); 
public delegate void Action&lt;T&gt;(T arg); 
public delegate void Action&lt;T1, T2&gt;(T1 arg1, T2 arg2); 
public delegate void Action&lt;T1, T2, T3&gt;(T1 arg1, 
                     T2 arg2, T3 arg3); 
public delegate void Action&lt;T1, T2, T3, T4&gt;(T1 arg1, 
                     T2 arg2, T3 arg3, T4 arg4); 

public delegate TResult Func(); 
public delegate TResult Func&lt;T&gt;(T arg1); 
public delegate TResult Func&lt;T1, T2&gt;(T1 arg1, T2 arg2); 
public delegate TResult Func&lt;T1, T2, T3&gt;(T1 arg1, 
                        T2 arg2, T3 arg3); 
public delegate TResult Func&lt;T1, T2, T3, T4&gt;(T1 arg1, 
                        T2 arg2, T3 arg3, T4 arg4);</pre>

<p>(Note that the above delegates are defined in .NET 3.5. In .NET 2.0 &amp; 3.0, only <code lang="cs">public delegate void Action&lt;T&gt;(T arg)</code> is defined.) Second, the <code>SmartThreadPool.QueueWorkItem()</code> method returns a reference to an object that implements the <code>IWorkItemResult&lt;TResult&gt;</code> interface. The caller can use this object to get the result of the work item. The interface is similar to the <code>IAsyncResult</code> interface:</p>

<pre lang="cs">public interface IWorkItemResult&lt;TResult&gt;
{ 
    /// Get the result of the work item. 
    /// If the work item didn't run yet then the caller waits
    /// until timeout or until the cancelWaitHandle is signaled. 
    /// If the work item threw then GetResult() will rethrow it. 
    /// Returns the result of the work item. 
    /// On timeout throws WorkItemTimeoutException. 
    /// On cancel throws WorkItemCancelException.
    TResult GetResult(
        int millisecondsTimeout,
        bool exitContext,
        WaitHandle cancelWaitHandle); 
    
    /// Some of the GetResult() overloads
    /// get Exception as an output parameter. 
    /// In case the work item threw
    /// an exception this parameter is filled with 
    /// it and the GetResult() returns null. 
    /// These overloads are provided
    /// for performance reasons. It is faster to 
    /// return the exceptions as an output
    /// parameter than rethrowing it.
    TResult GetResult(..., out Exception e);
        
    /// Other GetResult() overloads.
    ...
    
    /// Gets an indication whether
    /// the asynchronous operation has completed.
    bool IsCompleted { get; }
    
    /// Returns the user-defined object
    /// that was provided in the QueueWorkItem.
    /// If the work item callback is Action<span class="code-SummaryComment">&lt;...&gt;
</span>    /// or Func<span class="code-SummaryComment">&lt;...&gt; the State value
</span>    /// depends on the WIGStartInfo.FillStateWithArgs.
    object State { get; }
    
    /// Cancel the work item execution.
    /// If the work item is in the queue, it won't execute
    /// If the work item is completed, it will remain completed
    /// If the work item is already cancelled it will remain cancelled
    /// If the work item is in progress,
    /// the result of the work item is cancelled.
    ///    (See the work item canceling section for more information)
    /// Param: abortExecution - When true send an AbortException
    /// to the executing thread.<span class="code-SummaryComment">&lt;/param&gt;
</span>    /// Returns true if the work item
    /// was not completed, otherwise false.
    bool Cancel(bool abortExecution);
    
    /// Get the work item's priority
    WorkItemPriority WorkItemPriority { get; }

    /// Returns the result, same as GetResult(). 
    /// Note that this property blocks the caller like GetResult(). 
    TResult Result { get; }

    /// Returns the exception, if occured, otherwise returns null.
    /// This function is not blocking like the Result property.
    object Exception { get; }
}</pre>

<p>If the work item callback is <code lang="cs">object WorkItemCallback(object state)</code>, then <code>IWorkItemResult</code> is returned, and <code>GetResult()</code> returns <code lang="cs">object</code>. Same as in previous versions.</p>

<p>If the work item callback is one of the <code>Func&lt;...&gt;</code> methods I mentioned above, the result of <code>QueueWorkItem</code> is <code>IWorkItemResult&lt;TResult&gt;</code>. So, the result of the work item is strongly typed.</p>

<p>If the work item callback is one of the <code>Action&lt;...&gt;</code> methods I mentioned above, the result of <code>QueueWorkItem</code> is <code>IWorkItemResult</code> and <code>GetResult()</code> always returns <code lang="cs">null</code>.</p>

<p>If the work item callback is <code>Action&lt;...&gt;</code> or <code>Func&lt;...&gt;</code> and <code>WIGStartInfo.FillStateWithArgs</code> is set to <code lang="cs">true</code>, then the <code>State</code> of the <code>IWorkItemResult</code> is initialized with a <code lang="cs">object []</code> that contains the work item arguments. Otherwise, the <code>State</code> is <code lang="cs">null</code>.</p>

<p>The <a href="#SimpleExample">code examples</a> in the section below show some snippets of how to use it.</p>

<p>To get the result of the work item, use the <code>Result</code> property or the <code>GetResult()</code> method. This method has several overloads. In the interface above, I have written only some of them. The other overloads use less parameters by giving default values. The <code>GetResult()</code> returns the result of the work item callback. If the work item hasn't completed, then the caller waits until one of the following occurs:</p>

<table width="550" class="ArticleTable">
<thead>
<tr>
<td width="266">GetResult() return reason</td>

<td width="344">GetResult() return value</td>
</tr>
</thead>

<tbody>
<tr>
<td>The work item has been executed and completed.</td>

<td>The result of the work item.</td>
</tr>

<tr>
<td height="39">The work item has been canceled.</td>

<td height="39">Throws <code>WorkItemCancelException</code>.</td>
</tr>

<tr>
<td height="39">The timeout expired.</td>

<td height="39">Throws <code>WorkItemTimeoutException</code>.</td>
</tr>

<tr>
<td>The <code>cancelWaitHandle</code> is signaled.</td>

<td>Throws <code>WorkItemTimeoutException</code>.</td>
</tr>

<tr>
<td>The work item threw an exception.</td>

<td>Throws <code>WorkItemResultException</code> with the work item's exception as the inner exception.</td>
</tr>
</tbody>
</table>

<p>There are two ways to wait for a single work item to complete:</p>

<ol>
<li>The following function uses the <code>GetResult()</code> method which blocks the caller until the result is available:</li>

<pre lang="cs">private void WaitForResult1(IWorkItemResult wir)
{
    wir.GetResult();
}</pre>

<li>The following function is not recommended, because it uses a busy wait loop. You can use it if you know what you are doing:</li>

<pre lang="cs">private void WaitForResult2(IWorkItemResult wir)
{
    while(!wir.IsCompleted)
    {
        Thread.Sleep(100);
    }
}</pre>
</ol>

<li><a name="Feature4"><strong>The caller can wait for multiple work items to complete</strong></a>.</li>

<p>This feature is very useful if you want to run several work items at once and then wait for all of them to complete. The <code>SmartThreadPool</code> class has two static methods for this: <code>WaitAny()</code> and <code>WaitAll()</code> (they have several overloads). Their signature is similar to the <code>WaitHandle</code> equivalent methods except that in the <code>SmartThreadPool</code> case, it gets an array of <code>IWaitableResult</code> (the <code>IWorkItemResult</code> interface inherits from <code>IWaitableResult</code>) objects instead of <code>WaitHandle</code> objects.</p>

<p>The following snippets show how to wait for several work item results at once. Assume <code>wir1</code> and <code>wir2</code> are of type <code>IWorkItemResult</code>. You can wait for both work items to complete:</p>

<pre lang="cs">// Wait for both work items complete 
SmartThreadPool.WaitAll(new IWaitableResult[] { wir1, wir2});</pre>

<p>Or, for any of the work items to complete:</p>

<pre lang="cs">// Wait for at least one of the work items complete 
SmartThreadPool.WaitAny(new IWaitableResult[] { wir1, wir2});</pre>

<p>The <code>WaitAll()</code> and <code>WaitAny()</code> methods are overloaded, so you can specify the timeout, the exit context, and <code>cancelWaitHandle</code> (just like in the <code>GetResult()</code> method mentioned earlier).</p>

<p><strong>Note</strong> that in order to use <code>WaitAny()</code> and <code>WaitAll()</code>, you need to work in MTA, because internally, I use <code>WaitHandle.WaitAny()</code> and <code>WaitHandle.WaitAll()</code> which require it. If you don't do that, the methods will throw an exception to remind you.</p>

<p><strong>Also note</strong> that Windows supports <code>WaitAny()</code> of up to 64 handles. <code>WaitAll()</code> is more flexible, and I re-implemented it so it is not limited to 64 handles.</p>

<p>See in the examples section below, the code snippets for <a href="#WaitForAllExample"><code>WaitAll</code></a> and <a href="#WaitForAnyExample"><code>WaitAny</code></a>.</p>

<li><a name="Feature5"><strong>A work item can be cancelled</strong></a> (this feature is enhanced).</li>

<p>This feature enables to cancel work items.</p>

<p>There are several options to cancel work items. To cancel a single work item, call <code>IWorkItemResult.Cancel()</code>. To cancel more than one, call <code>IWorkItemsGroup.Cancel()</code> or <code>SmartThreadPool.Cancel()</code>. All cancels works in O(1).</p>

<p>There is no guarantee that a work item will be cancelled, it depends on the state of the work item when the cancel is called and the cooperation of the work item. (Note that the work item's state I mention here has nothing to do with the state object argument provided in the <code>QueueWorkItem</code>.)</p>

<p>These are the possible states of a work item (defined in the <code>WorkItemState</code> enum):</p>

<ul class="enum">
<li><code>Queued</code> – The work item is waiting in a queue to be executed.</li>

<li><code>InProgress</code> – A thread from the pool is executing the work item.</li>

<li><code>Completed</code> – The work item execution has been completed.</li>

<li><code>Cancelled</code> – The work item has been cancelled.</li>
</ul>

<p>The cancel behavior depends on the state of the work item.</p>

<table class="ArticleTable">
<thead>
<tr>
<td width="140" align="center">Initial State</td>

<td width="99" align="center">Next State</td>

<td width="332" align="center">Notes</td>
</tr>
</thead>

<tbody>
<tr>
<td><code>Queued</code></td>

<td><code>Cancelled</code></td>

<td>A queued work item becomes cancelled and is not executed at all.</td>
</tr>

<tr>
<td><code>InProgress</code></td>

<td><code>Cancelled</code></td>

<td>An executing work item becomes cancelled even if it completes its execution!</td>
</tr>

<tr>
<td><code>Completed</code></td>

<td><code>Completed</code></td>

<td>A completed work item stays completed.</td>
</tr>

<tr>
<td><code>Cancelled</code></td>

<td><code>Cancelled</code></td>

<td>A cancelled work item stays cancelled.</td>
</tr>
</tbody>
</table>

<p>A cancelled work item throws a <code>WorkItemCancelException</code> when its <code>GetResult()</code> method is called.</p>

<p>The behavior of <code>Cancel()</code> when the work item is in <code>Completed</code> or <code>Cancelled</code> states is straightforward, so I won't get into the details. A queued work item is marked as cancelled and is discarded once a thread from the pool dequeues it.</p>

<p>If a work item is in the <code>InProgress</code> state, then the behavior depends on the value of <code>abortExecution</code> in the <code>Cancel</code> call. When <code>abortExecution</code> is <code lang="cs">true</code>, a <code>Thread.Abort()</code> will be called upon the executing thread. When <code>abortExecution</code> is <code lang="cs">false</code>, the work item method is responsible to sample the <code>SmartThreadPool.IsWorkItemCanceled</code> static method and quit. Note that, in both cases, the work item is cancelled, and throws a <code>WorkItemCancelException</code> on <code>GetResult()</code>.</p>

<p>Here is an example of a cooperative work item:</p>

<pre lang="cs">private void DoWork()
{
    // Do something here.

    // Sample SmartThreadPool.IsWorkItemCanceled
    if (SmartThreadPool.IsWorkItemCanceled)
    {
        return;
    }

    // Sample the SmartThreadPool.IsWorkItemCanceled in a loop
    while (!SmartThreadPool.IsWorkItemCanceled)
    {
        // Do some work here
    }
}</pre>

<li><a name="Feature6"><strong>The caller thread's context is used when the work item is executed (limited)</strong></a>.</li>

<p>This feature should be elementary, but it is not so simple to implement. In order to pass the thread's context, the caller thread's <code>CompressedStack</code> should be passed. This is impossible since Microsoft blocks this option with security. Other parts of the thread's context can be passed. These include:</p>

<ul>
<li><code>CurrentCulture</code> - The culture of the thread.</li>

<li><code>CurrentUICulture</code> - The culture used by the resource manager to look up culture-specific resources at run time.</li>

<li><code>CurrentPrincipal</code> - The current principal (for role-based security).</li>

<li><code>CurrentContext</code> - The current context in which the thread is executing (used in remoting).</li>
</ul>

<p>The first three belong to the <code>System.Threading.Thread</code> class (static or instance), and are get/set properties. However, the last one is a read only property. In order to set it, I used Reflection, which slows down the application. If you need this context, just remove the comments from the code.</p>

<p>To simplify the operation of capturing the context and then applying it later, I wrote a special class that is used internally and does all that stuff. The class is called <code>CallerThreadContext</code>, and it is used internally. When Microsoft unblocks the protection on the <code>CompressedStack</code>, I will add it there.</p>

<p>The caller thread's context is stored when the work item is created, within the <code>EnqueueWorkItem()</code> method. Each time a thread from the pool executes a work item, the thread's context changes in the following order:</p>

<ol>
<li>The current thread context is captured.</li>

<li>The caller thread context is applied.</li>

<li>The work item is executed.</li>

<li>The current old thread context is restored.</li>
</ol>

<li><strong>Usage of <a name="Feature7">minimum number of Win32 event handles, so the handle count of the application won't explode</a></strong>.</li>

<p>The seventh feature is a result of Kevin's comment on the earlier version of Smart Thread Pool. It seemed that the test application consumed a lot of handles (Handle Count in the Task Manager) without freeing them. After a few tests, I got to the conclusion that the <code>Close()</code> method of the <code>ManualResetEvent</code> class doesn't always release the Win32 event handle immediately, and waits for the garbage collector to do that. Hence, running the GC explicitly releases the handles.</p>

<p>To make this problem less acute, I used a new approach. First, I wanted to create less number of handles; second, I wanted to reuse the handles I had already created. Therefore, I need not expose any <code>WaitHandle</code>, but use them internally and then close them.</p>

<p>In order to create fewer handles, I created the <code>ManualResetEvent</code> objects only when the user asks for them (lazy creation). For example, if you don't use the <code>GetResult()</code> of the <code>IWorkItemResult</code> interface, then a handle is not created. Using <code>SmartThreadPool.WaitAll()</code> and <code>SmartThreadPool.WaitAny()</code> creates a handle.</p>

<p>The work item queue creates a lot of handles since each new wait for a work item creates a new <code>ManualResetEvent</code>. Hence, a handle for each work item. The waiters of the queue are always the same threads, and a thread cannot wait more than once. So now, every thread in the thread pool has its own <code>ManualResetEvent</code> and reuses it. To avoid coupling of the work items queue and the thread pool implementation, the work items queue stores a context inside the TLS (Thread Local Storage) of the thread.</p>

<li><a name="Feature8"><strong>Work item can have a PostExecute callback. This is a method that will be called right after the work item execution has been completed</strong></a>.</li>

<p>A <code>PostExecute</code> is a callback method that is called right after the work item execution has been completed. It runs in the same context of the thread that executes the work item. The user can choose the cases in which <code>PostExecute</code> is called. The options are represented in the <code>CallToPostExecute</code> flagged enumerator:</p>

<pre lang="cs">[Flags]
public enum CallToPostExecute
{
    Never                    = 0x00,
    WhenWorkItemCanceled     = 0x01,
    WhenWorkItemNotCanceled  = 0x02,
    Always = WhenWorkItemCanceled | WhenWorkItemNotCanceled,
}</pre>

<p>Explanation:</p>

<ul class="enum">
<li><code>Never</code> – Don't run <code>PostExecute</code>.</li>

<li><code>WhenWorkItemCanceled</code> - Run <code>PostExecute</code> only when the work item has been canceled.</li>

<li><code>WhenWorkItemNotCanceled</code> - Run <code>PostExecute</code> only when the work item has not been canceled.</li>

<li><code>Always</code> – Always run <code>PostExecute</code>.</li>
</ul>

<p><code>SmartThreadPool</code> has a default <code>CallToPostExecute</code> value of <code>CallToPostExecute.Always</code>. This can be changed during the construction of <code>SmartThreadPool</code> in the <code>STPStartInfo</code> class argument. Another way to give the <code>CallToPostExecute</code> value is in one of the <code>SmartThreadPool.QueueWorkItem</code> overloads. Note that, as opposed to the <code>WorkItem</code> execution, if an exception has been thrown during <code>PostExecute</code>, then it is ignored. <code>PostExecute</code> is a delegate with the following signature:</p>

<pre lang="cs">public delegate void PostExecuteWorkItemCallback(IWorkItemResult wir);</pre>

<p>As you can see, <code>PostExecute</code> receives an argument of type <code>IWorkItemResult</code>. It can be used to get the result of the work item, or any other information made available by the <code>IWorkItemResult</code> interface.</p>

<li><a name="Feature9"><strong>The user can choose to automatically dispose off the state object that accompanies the work item</strong></a>.</li>

<p>When the user calls <code>QueueWorkItem</code>, he/she can provide a state object. The state object usually stores specific information, such as arguments that should be used within the <code>WorkItemCallback</code> delegate.</p>

<p>The state object life time depends on its contents and the user's application. Sometimes, it is useful to dispose off the state object just after the work item has been completed. Especially if it contains unmanaged resources.</p>

<p>For this reason, I added a boolean to <code>SmartThreadPool</code> that indicates to call <code>Dispose</code> on the state object when the work item has been completed. The boolean is initialized when the thread pool is constructed with <code>STPStartInfo</code>. <code>Dispose</code> is called only if the state object implements the <code>IDisposable</code> interface. <code>Dispose</code> is called after the <code>WorkItem</code> has been completed and its <code>PostExecute</code> has run (if a <code>PostExecute</code> exists). The state object is disposed even if the work item has been canceled or the thread pool has been shutdown.</p>

<p><strong>Note</strong> that this feature only applies to the <code>state</code> argument that comes with <code>WorkItemCallback</code>, it doesn't apply to the arguments supplied in <code>Action&lt;...&gt;</code> and <code>Func&lt;...&gt;</code>!!!</p>

<li><a name="Feature10"><strong>The user can wait for the Smart Thread Pool / Work Items Group to become idle. </strong></a>
<p>This feature enables the user to wait for a Smart Thread Pool or a Work Items Group to become idle. They become idle when the work items queue is empty and all the threads have completed executing all their work items.</p>

<p>This is useful in case you want to run a batch of work items and then wait for all of them to complete. It saves you from handling the <code>IWorkItemResult</code> objects in case you just want to wait for all of the work items to complete.</p>

<p>The <code>SmartThreadPool</code> and WorkItemsGroup classes both implement the <code>IWorkItemsGroup</code> interface which defines the <code>WaitForIdle</code> methods.</p>

<p>To take advantage of this feature, use the <code>IWorkItemsGroup.WaitForIdle()</code> method (both <code>SmartThreadPool</code> and WorkItemsGroup implement the <code>IWorkItemsGroup</code> interface which defines the <code>WaitForIdle</code> methods). It has several overloads which provide a timeout argument. The <code>WaitForIdle()</code> method is not <code lang="cs">static</code>, and should be used on a <code>SmartThreadPool</code> instance.</p>

<p><code>SmartThreadPool</code> always keeps track of how many work items it has. When a new work item is queued, the number is incremented. When a thread completes a work item, the number is decremented. The total number of work items includes the work items in the queue and the work items that the threads are currently working on.</p>

<p>The <code>WaitForIdle()</code> mechanism works with a private <code>ManualResetEvent</code>. When a work item is queued, the <code>ManualResetEvent</code> is reset (changed to non-signaled state). When the work items count becomes zero (initial state of the Smart Thread Pool), the <code>ManualResetEvent</code> is set (changed to signaled state). The <code>WaitForIdle()</code> method just waits for the <code>ManualResetEvent</code> to implement its functionality.</p>

<p>See the <a href="#WaitForIdleExample">example</a> below.</p>
</li>

<li><a name="Feature11"><strong>Exception handling has been changed, so if a work item throws an exception, it is rethrown at <code>GetResult()</code>, rather than firing an <code>UnhandledException</code> event. Note that <code>PostExecute</code> exceptions are always ignored</strong></a>. 
<p>After I did some reading about delegates and their implementation, I decided to change the way <code>SmartThreadPool</code> treats exceptions. In the previous versions, I used an event driven mechanism. Entities were registered to the <code>SmartThreadPool.UnhandledException</code> event, and when a work item threw an exception, this event was fired. This is the behavior of Toub’s thread pool.</p>

<p>.NET delegates behave differently. Instead of using an event driven mechanism, it re-throws the exception of the delegated method at <code>EndInvoke()</code>. Similarly, the <code>SmartThreadPool</code> exception mechanism is changed so that exceptions are no longer fired by the <code>UnhandledException</code> event, but rather re-thrown again when <code>IWorkItemResult.GetResult()</code> is called.</p>

<p>Note that exceptions slow down .NET and degrade the performance. .NET works faster when no exceptions are thrown at all. For this reason, I added an output parameter to some of the <code>GetResult()</code> overloads, so the exception can be retrieved rather than re-thrown. The work item throws the exception anyway, so re-throwing it will be a waste of time. As a rule of thumb, it is better to use the output parameter than catch the re-thrown exception.</p>

<p><code>GetResult()</code> can be called unlimited number of times, and it re-throws the same exception each time.</p>

<p>Note that <code>PostExecute</code> is called as and when needed, even if the work item has thrown an exception. Of course, the <code>PostExecute</code> implementation should handle exceptions if it calls <code>GetResult()</code>.</p>

<p>Also note that if <code>PostExecute</code> throws an exception, then its exception is ignored.</p>

<p>See the <a href="#CatchExceptionExample">example</a> below.</p>
</li>

<li><a name="Feature12"><strong>Work items have priority</strong></a>.</li>

<p>Work items priority enables the user to order work items at run time. Work items are ordered by their priority. High priority is treated first. There are five priorities:</p>

<pre lang="cs">public enum WorkItemPriority 
{ 
    Lowest, 
    BelowNormal, 
    Normal, 
    AboveNormal, 
    Highest,
}</pre>

<p>The default priority is <code>Normal</code>.</p>

<p>The implementation of priorities is quite simple. Instead of using one queue that keeps the work items sorted inside, I used one queue for each priority. Each queue is a FIFO. When the user enqueues a work item, the work item is added to the queue with a matching priority. When a thread dequeues a work item, it looks for the highest priority queue that is not empty.</p>

<p>This is the easiest solution to sort the work items.</p>

<li><a name="Feature13"><strong>The caller thread's HTTP context can be used when the work item is executed</strong></a>.</li>

<p>This feature improves 6, and was implemented by Steven T. I just replaced my code with that implementation.</p>

<p>With this feature, the Smart Thread Pool can be used with ASP.NET to pass the context of HTTP between the caller thread and the thread in the pool that will execute the work item.</p>

<li><a name="Feature14"><strong>Work items group</strong></a>.</li>

<p>This feature enables the user to execute a group of work items specifying the maximum level of concurrency.</p>

<p>For example, assume that your application uses several resources, the resources are not thread safe, so only one thread can use a resource at a time. There are a few solutions to this, from creating one thread that uses all resources to creating a thread per resource. The first solution doesn’t harness the power of parallelism, the latter solution is too expensive (many threads) if the resources are idle most of the time.</p>

<p>The Smart Thread Pool solution is to create a WorkItemsGroup per resource, with a concurrency of one. Each time a resource needs to do some work, a work item is queued into its WorkItemsGroup. The concurrency of the WorkItemsGroup is one, so only one work item can run at a time per resource. The number of threads dynamically changes according to the load of the work items.</p>

<p>Here is a code snippet to show how this works:</p>

<pre lang="cs">...

// Create a SmartThreadPool
SmartThreadPool smartThreadPool = new SmartThreadPool();

// Create a work items group that processes 
// one work item at a time for resource 1
IWorkItemsGroup wigPrinter1 = smartThreadPool.CreateWorkItemsGroup(1);

// Create a work items group that processes 
// one work item at a time for resource 2
IWorkItemsGroup wigPrinter2 = smartThreadPool.CreateWorkItemsGroup(1);

// Queue work items to resources
wigPrinter1.QueueWorkItem(Print, printer1, lessons);
wigPrinter1.QueueWorkItem(Print, printer1, homework);
wigPrinter2.QueueWorkItem(Print, printer2, blueprints);

...

// Print prototype
void Print(Printer printer, Document document) {...}

...</pre>

<p>As you can see from the snippet, a WorkItemsGroup is attached to an instance of a Smart Thread Pool. The Work Items Group doesn't have threads of its own, but rather uses the threads of the Smart Thread Pool. It also has an interface similar to the Smart Thread Pool, so it can be used in the same way and replaced when needed.</p>

<p>The WorkItemsGroup has a priority queue (the same as the <code>SmartThreadPool</code>). The queue stores the work items of the WorkItemsGroup. The WorkItemsGroup dequeues the work item with the highest priority at the head of the queue and queues it into the <code>SmartThreadPool</code> with the same priority.</p>

<p>The WorkItemsGroup is responsible for managing the maximum level of concurrency of its work items. Once a work item is queued into the WorkItemsGroup, it checks how many work items it has in the <code>SmartThreadPool</code>. If this number is less than the maximum level of concurrency, it queues the work item into the <code>SmartThreadPool</code>. If this number is equal (it cannot be greater), then the WorkItemsGroup stores the work item in its own priority queue.</p>

<p>In case the WorkItemsGroup is created in suspend mode, it will store the work items in its queue until it is started. When it is started, it will queue the work items into the <code>SmartThreadPool</code> up to the maximum level of concurrency.</p>

<p>Note that the WorkItemsGroup only has a maximum level of concurrency and not a minimum or exact value. It is possible to have a concurrency level of 3, and have non work items executing, since they are waiting in the <code>SmartThreadPool</code> queue.</p>

<p>To accomplish the concurrency level, the WorkItemsGroup registers to the completion event of its work items. The event is used internally, and is not exposed to the user. Once registered, the WorkItemsGroup will get an event when its work item is completed. The event will trigger the WorkItemsGroup to queue more work items into the <code>SmartThreadPool</code>. The event is the only way to accomplish the concurrency level. When I tried to do it with <code>PostExecute</code>, I got fluctuating <code>WaitForIdle</code>.</p>

<p>Another advantage of the WorkItemsGroup is that it can cancel all its work items that haven't been executed yet in one method with a complexity of O(1). The WorkItemsGroup does so by attaching an object to each one of its work items that indicates if the WorkItemsGroup has been cancelled. When a work item is about to be executed, it is asked for its current state (<code>InQueue</code>, <code>InProgress</code>, <code>Completed</code>, or <code>Canceled</code>). The final state considers this object's value to know if the work item was cancelled.</p>

<p>The Work Items Group can also be used as a conjunction point. Say, you want to accomplish a task by splitting it to subtasks. Once the subtasks are completed, a new task is issued and split to subtasks too. This can be achieved by using the <code>OnIdle</code> event of the WorkItemsGroup. See the <a href="#WorkItemsGroupExample">examples</a> below.</p>

<p>See the WorkItemsGroupDemo demo in the source code solution.</p>

<p><img width="550" height="648" src="WorkItemsGroup.jpg" /></p>

<li><a name="Feature15"><strong>The caller can create thread pools and work item groups in suspended state</strong></a>.</li>

<p>When a Smart Thread Pool is created, by default, it starts its threads immediately. However, sometimes, you need to queue a few work items and only then start executing them.</p>

<p>In these cases, you can create the Smart Thread Pool and the Work Items Group in a suspended state. When you need to execute the work items, just call the <code>Start()</code> method. The same method exists in the Work Items Group for the same purpose.</p>

<p>Note that if you create a suspended Work Items Group in a suspended Smart Thread Pool, starting the Work Items Group won't execute the work items until the Smart Thread Pool is started.</p>

<li><a name="Feature16"><strong>Threads have priority</strong></a>.</li>

<p><code>STPStartInfo</code> contains a property that defines the priority in which the threads are started in the <code>SmartThreadPool</code>. Use it if you know what you are doing. Playing with threads priority may end up with dead locks, live lock, and days locked <img align="top" alt="Frown | :-(" src="http://www.codeproject.com/script/Forums/Images/smiley_frown.gif" /> .</p>

<li><a name="Feature17"><strong><code>MaxThreads</code>/<code>MinThreads</code>/<code>Concurrency</code> can be changed at run time</strong></a>.</li>

<p>This addition allows the user to control the concurrency of work items execution. It is useful to make the STP adaptable.</p>

<p>To execute more work items in parallel, increment the concurrency. To limit the number of executed work items and/or lower the CPU usage, decrement the concurrency.</p>

<p>This option is available in the <code>SmartThreadPool</code> and in the WorkItemsGroup with the <code>IWokItemsGroup</code> interface:</p>

<pre lang="cs">public interface IWorkItemsGroup
{
    ...
    int Concurrency { get; set; }
    ...
}</pre>

<p>The value of <code>Concurrency</code> must be positive.</p>

<p>Although <code>Concurrency</code> has the same meaning and the same behavior as in the <code>SmartThreadPool</code> and in the WorkItemsGroup, it’s implemented differently.</p>

<p><code>SmartThreadPool</code>’s <code>Concurrency</code> is equivalent to the <code>MaxThreads</code> property. When <code>Concurrency</code> is incremented, the <code>SmartThreadPool</code> can create more threads to handle its work items up to the <code>Concurrency</code> limit. The creation of thread, in this case, is immediate. The threads are still created as explained in <a href="#Feature2">section 2</a>.</p>

<p>When <code>Concurrency</code> is decremented, the <code>SmartThreadPool</code> doesn’t create new threads and let existing threads to be terminated in order to decrement the number of threads in the thread pool. Note that the lowering of <code>Concurrency</code> may take a while to take effect, since we need to wait for work items to complete. <code>SmartThreadPool</code> doesn’t abort a thread actively, but waits passively until it quits.</p>

<p>WorkItemsGroup’s <code>Concurrency</code> is responsible for how many work items may be handled in parallel in the <code>SmartThreadPool</code>, as explained in <a href="#Feature14">section 14</a>. When <code>Concurrency</code> is incremented, more work items are queued to the <code>SmartThreadPool</code>. When <code>Concurrency</code> is decremented, the WorkItemsGroup stops to queue work items until the number of work items in the <code>SmartThreadPool</code> of this WorkItemsGroup is lower than the WorkItemsGroup’s <code>Concurrency</code>.</p>

<p>In addition, <code>SmartThreadPool</code> also lets the <code>MinThreads</code> property to be changed after its creation. When <code>MinThreads</code> is created, the number of threads in the pool is raised so it will be at least <code>MinThreads</code>.</p>

<p>The number of <code>MaxThreads</code> must be greater or equal to <code>MinThreads</code>. If <code>MaxThreads</code> is set to a number lower than <code>MinThreads</code>, then <code>MinThreads</code> is also set to the new value of <code>MaxThreads</code>. And, vice versa for <code>MinThreads</code>.</p>

<li><a name="Feature18"><strong>Improved Cancel behavior</strong></a>.</li>

<p><a href="#Feature5">(See section 5)</a>.</p>

<li><a name="Feature19"><strong>Threads initialization and termination generate events</strong></a>.</li>

<p>This functionality enables the user to execute code when a thread is created or terminated in the thread pool. The code is executed within the thread’s context. This feature is exposed as new events in the <code>SmartThreadPool</code> class:</p>

<pre lang="cs">// A delegate to call after a thread is created,
// but before it's first use.
public delegate void ThreadInitializationHandler();

// A delegate to call when a thread is about to exit,
// after it is no longer 
// belong to the pool.
public delegate void ThreadTerminationHandler();

public event ThreadInitializationHandler OnThreadInitialization
{...}

public event ThreadTerminationHandler OnThreadTermination;
{...}</pre>

<p>The <code>OnThreadInitialization</code> event is fired when a thread is created and added to the threads pool. The event is called from the created thread. In this event, the user should add code to initialize resources that are used by the thread, and should be initialized once per thread instead of once per work item.</p>

<p>The <code>OnThreadTermination</code> event is fired when a thread leaves the threads pool. The event is called from the terminated thread. In this event, the user has the opportunity to clean up the resources that were initialized earlier in the <code>OnThreadInitialization</code> event.</p>

<li><a name="Feature20"><strong>Supports Windows CE (limited)</strong>.</a></li>

<p>The SmartThreadPool project has a similar project named SmartThreadPoolCE. This version of the SmartThreadPool can be run on Windows CE.</p>

<p>It has the same features as the PC version, but it doesn't fully work yet. I still have an issue with the threads scheduling, since the thread idle stuff explained in section 2 doesn't work on Windows CE.</p>

<p><img width="346" height="586" src="WindowsCE.jpg" /></p>

<li><a name="Feature21"><strong>SmartThreadPool and IWorkItemsGroup has the IsIdle flag</strong></a>.</li>

<p>This flag enables the user to poll the Smart Thread Pool / Work Items Group if they are idle.</p>

<li><a name="Feature22"><strong>Supports Action&lt;T&gt; and Func&lt;T&gt; (strongly typed work items)</strong></a>.</li>

<p><a href="#Feature3">(See section 3)</a>.</p>

<li><a name="Feature23"><strong>Supports Silverlight</strong></a>.</li>

<p>Add a reference to <em>SmartThreadPoolSL.dll</em> in your code and use it.</p>

<p><img width="550" height="641" src="Silverlight.jpg" /></p>

<li><a name="Feature24"><strong>Supports Mono</strong></a>.</li>

<p>Add a reference to <em>SmartThreadPoolMono.dll</em> in your code and use it.</p>

<p>Note that the binaries of Mono were compiled on Windows with Visual Studio 2008.</p>

<p><img width="550" height="344" src="Mono.jpg" /></p>

<li><a name="Feature25"><strong>Internal performance counters</strong></a>.</li>

<p>The internal performance counter should be used on platforms that don't support Performance Counters, such as Windows CE, Silverlight, and Mono.</p>

<p>The internal performance counters are variables inside STP that collect the data. To enable them, set <code>STPStartInfo.EnableLocalPerformanceCounters</code> to <code lang="cs">true</code>. I use this feature in the new demos (WindowsCE, Silverlight, and Mono).</p>

<li><a name="Feature26"><strong>Join, Choice, and Pipe</strong></a>.</li>

<p>The new methods are added to the <code>SmartThreadPool</code> class and implemented using WorkItemsGroup. Their purpose is to simplify the initiation of a parallel task.</p>

<ul>
<li><code>Join</code> - Executes several work items and waits for all of them to complete <a href="#JoinExample">(Join example)</a>.</li>

<li><code>Choice</code> - Executes several work items and returns when the first one completes <a href="#ChoiceExample">(Choice example)</a>.</li>

<li><code>Pipe</code> - Executes several work items sequentially and waits until the last work item completes <a href="#PipeExample">(Pipe example)</a>.&nbsp;&nbsp;&nbsp;&nbsp;</li></ul><li><a name="Feature27"><strong>Work item timeout (passive)</strong></a>.&nbsp;</li>

<p>This feature lets the user specify a timeout for the work item to complete, in milliseconds. When the timeout expires, the work item is cancelled automatically if it didn't complete. The cancel works the same as a call to <code>Cancel</code> with the <code>abortExecution</code> argument set to <code lang="cs">false</code> (this is why the timeout is passive).</p>

<p>To sample the cancel, use <code>SmartThreadPool.IsWorkItemCanceled</code> which is a static property, or you can use <code>SmartThreadPool.AbortOnWorkItemCancel</code> which checks if the current work item is cancelled, and if so, abort the thread (<code>Thread.CurrentThread.Abort()</code>).</p>

<p>See the timeout <a href="#TimeoutExample">example</a> below.</p>
<li><a name="Feature28"><strong>Enabled to set threads IsBackground</strong></a></li>
<p>This featue enables to set the <code>IsBackground</code> of the STP threads. The default is <code>true</code>.</p>
<p>To use it:<br />
	        </p><pre lang="cs">STPStartInfo stpStartInfo = new STPStartInfo();
stpStartInfo.AreThreadsBackground = false; 
SmartThreadPool stp = new SmartThreadPool(stpStartInfo);
</pre>
<p>

</p><li><a name="Feature29"><strong>Enabled to set threads ApartmentState</strong></a></li>
<p>This featue enables to set the <code>ApartmentState</code> of the STP threads. The default is not to set.</p>
<p>To use it:<br />
</p><pre lang="cs">STPStartInfo stpStartInfo = new STPStartInfo();
stpStartInfo.ApartmentState = ApartmentState.MTA;
SmartThreadPool stp = new SmartThreadPool(stpStartInfo);</pre><ol><p>
</p>
</ol>
<li><a name="Feature30"><strong>Support Windows Phone (limited)</strong></a></li>
<p>Add reference to SmartThreadPoolWP.dll in your code and use it.</p>
<p><img width="404" height="749" src="WindowsPhone.png" /></p>

<li><a name="Feature31"><strong>Enabled to set thread MaxStackSize</strong></a></li>
<p>With this feature the user is able to set the MaxStackSize of the threads in the thread pool</p>
<p>To use it set the MaxStackSize member in the STPStartInfo.</p>
<p>
</p><pre lang="cs">STPStartInfo stpStartInfo = new STPStartInfo();
stpStartInfo.MaxStackSize = 1024*1024;
SmartThreadPool stp = new SmartThreadPool(stpStartInfo);
</pre>
<p>
</p></ol>

<h2>When to use?</h2>

<p>The Smart Thread Pool is good when your work items don't do too much, but wait for events, IOs, sockets, etc. This means that the work items don't use CPU, but run for a long time. It is also good when you don't need to keep alive too many threads in the air all the time. If your work items do a short time work, then use the .NET ThreadPool. If you have a constant heavy load of work, then use Toub's thread pool and define the maximum number of threads accordingly.</p>

<h2>How to use?</h2>

<p>When the Smart Thread Pool or Work Items Group is created, it requires a few parameters; when a value is not provided, a default value is used.</p>

<table class="ArticleTable">
<thead>
<tr>
<td>Value name</td>

<td>Default value</td>

<td>Smart Thread Pool</td>

<td>Work Items Group</td>

<td>Description</td>
</tr>
</thead>

<tbody>
<tr>
<td><code>IdleTimeout</code></td>

<td>60 seconds</td>

<td>Used</td>

<td>Not used</td>

<td>Idle timeout</td>
</tr>

<tr>
<td><code>MaxWorkerThreads</code></td>

<td>25</td>

<td>Used</td>

<td>Not used</td>

<td>Maximum number of threads</td>
</tr>

<tr>
<td><code>MinWorkerThreads</code></td>

<td>0</td>

<td>Used</td>

<td>Not used</td>

<td>Minimum number of threads</td>
</tr>

<tr>
<td><code>UseCallerCallContext</code></td>

<td><code lang="cs">false</code></td>

<td>Used</td>

<td>Used</td>

<td>Use caller thread call context</td>
</tr>

<tr>
<td><code>UseCallerHttpContext</code></td>

<td><code lang="cs">false</code></td>

<td>Used</td>

<td>Used</td>

<td>Use caller thread HTTP context</td>
</tr>

<tr>
<td><code>DisposeOfStateObjects</code></td>

<td><code lang="cs">false</code></td>

<td>Used</td>

<td>Used</td>

<td>Dispose of the state objects (if the state implements <code lang="cs">IDisposable</code>)</td>
</tr>

<tr>
<td><code>CallToPostExecute</code></td>

<td><code class="SmallText">CallToPostExecute.Always</code></td>

<td>Used</td>

<td>Used</td>

<td>Call to <code>PostExecute</code></td>
</tr>

<tr>
<td><code class="SmallText">PostExecuteWorkItemCallback</code></td>

<td><code lang="cs">null</code> (Do nothing)</td>

<td>Used</td>

<td>Used</td>

<td><code>PostExecute</code> method</td>
</tr>

<tr>
<td><code>StartSuspended</code></td>

<td><code lang="cs">false</code></td>

<td>Used</td>

<td>Used</td>

<td>Start suspended</td>
</tr>

<tr>
<td><code lang="cs">FillStateWithArgs</code></td>

<td><code lang="cs">false</code></td>

<td>Used</td>

<td>Used</td>

<td>Fill state with args (<code>Action&lt;T&gt;</code> and <code>Func&lt;T&gt;</code>)</td>
</tr>

<tr>
<td><code lang="cs">ThreadPriority</code></td>

<td><code class="SmallText">ThreadPriority.Normal</code></td>

<td>Used</td>

<td>Not used</td>

<td>Thread priority in thread pool (not supported in Mono)</td>
</tr>

<tr>
<td><code lang="cs">WorkItemPriority</code></td>

<td><code class="SmallText">WorkItemPriority.Normal</code></td>

<td>Used</td>

<td>Used</td>

<td>Work item default priority</td>
</tr>

<tr>
<td><code class="SmallText">PerformanceCounterInstanceName</code></td>

<td><code lang="cs">null</code></td>

<td>Used</td>

<td>Not used</td>

<td>Performance counter instance name</td>
</tr>

<tr>
<td><code class="SmallText">EnableLocalPerformanceCounters</code></td>

<td><code lang="cs">false</code></td>

<td>Used</td>

<td>Not used</td>

<td>Enable local performance counters (for platforms which don't support performance counters)</td>
</tr>
</tbody>
</table>

<p>Once defined in the construction, they cannot be changed. So, choose their values according to your needs. The minimum number of threads should be proportional to the number of work items that you want to handle at normal times. The maximum number of threads should be proportional to the number of work items that you want to handle at peak times. The idle timeout should be proportional to the peak length time.</p>

<h2>Code examples</h2>

<p>Creating a Smart Thread Pool instance:</p>

<pre lang="cs">SmartThreadPool smartThreadPool = 
 new SmartThreadPool(
    10*1000,    // Idle timeout in milliseconds
    25,         // Threads upper limit
    5,          // Threads lower limit
    true);      // Use caller thread context</pre>

<p>Another way to create an instance:</p>

<pre lang="cs">// Create a STPStartInfo object
STPStartInfo stpStartInfo = new STPStartInfo();

// Change the defaults of the STPStartInfo object
stpStartInfo.DisposeOfStateObjects = true;

// Create the SmartThreadPool instance
SmartThreadPool smartThreadPool = 
        new SmartThreadPool(stpStartInfo);</pre>

<h2>Using the Smart Thread Pool</h2>

<p>The following snippet is a simple example. The user queues a work item and then gets the result. Note that the <code>Result</code> property blocks until a result is available or the work item is cancelled:<a name="SimpleExample"></a></p>

<pre lang="cs">public class SimpleExample
{
    public void DoWork(int [] numbers) 
    { 
        SmartThreadPool smartThreadPool = new SmartThreadPool();

        // Queue the work item
        IWorkItemResult&lt;double&gt; wir = smartThreadPool.QueueWorkItem(
                    new Func&lt;int[], double&gt;(CalcAverage), numbers); 

        // Do some other work here

        // Get the result of the operation
        double average = wir.Result;

        smartThreadPool.Shutdown();
    } 

    // Do the real work 
    private double CalcAverage(int [] numbers)
    { 
        double average = 0.0;
        
        // Do the real work here and put 
        // the result in 'result'

        return average;
    }
}</pre>

<p>This example shows how you can wait for specific work items to complete. The user queues two work items, waits for both of them to complete, and then gets the results:<a name="WaitForAllExample"></a></p>

<pre lang="cs">public class WaitForAllExample
{
    public void DoWork() 
    { 
        SmartThreadPool smartThreadPool = new SmartThreadPool();

        IWorkItemResult wir1 = 
            smartThreadPool.QueueWorkItem(new 
            WorkItemCallback(this.DoSomeWork1), null);

        IWorkItemResult wir2 = 
            smartThreadPool.QueueWorkItem(new 
            WorkItemCallback(this.DoSomeWork2), null);

        bool success = SmartThreadPool.WaitAll(
               new IWorkItemResult [] { wir1, wir2 });

        if (success)
        {
            int result1 = (int)wir1.Result;
            int result2 = (int)wir2.Result;
        }

        smartThreadPool.Shutdown();
    } 

    private object DoSomeWork1(object state)
    { 
        return 1;
    }

    private object DoSomeWork2(object state)
    { 
        return 2;
    }
}</pre>

<p>This example shows how you can wait for one of the specific work items to complete. The user queues two work items, waits for one of them to complete, and then gets its result<a name="WaitForAnyExample"></a>:</p>

<pre lang="cs">public class WaitForAnyExample
{
    public void DoWork() 
    { 
        SmartThreadPool smartThreadPool = new SmartThreadPool();

        IWorkItemResult wir1 = 
            smartThreadPool.QueueWorkItem(new 
            WorkItemCallback(this.DoSomeWork1), null);

        IWorkItemResult wir2 = 
            smartThreadPool.QueueWorkItem(new 
            WorkItemCallback(this.DoSomeWork2), null);

        IWorkItemResult [] wirs = 
                new IWorkItemResult [] { wir1, wir2 };

        int index = SmartThreadPool.WaitAny(wirs);

        if (index != WaitHandle.WaitTimeout)
        {
            int result = (int)wirs[index].Result;
        }

        smartThreadPool.Shutdown();
    } 

    private object DoSomeWork1(object state)
    {
        return 1;
    }

    private object DoSomeWork2(object state)
    { 
        return 1;
    }
}</pre>

<p>The following example shows the use of <code>WaitForIdle()</code>. We just queue all the work items and then wait for all of them to complete. Note that we ignore the results of the work items:<a name="WaitForIdleExample"></a></p>

<pre lang="cs">public class WaitForIdleExample
{
    public void DoWork(object [] states) 
    { 
        SmartThreadPool smartThreadPool = new SmartThreadPool();

        foreach(object state in states)
        {
            smartThreadPool.QueueWorkItem(new 
                WorkItemCallback(this.DoSomeWork), state);
        }

        // Wait for the completion of all work items
        smartThreadPool.WaitForIdle();

        smartThreadPool.Shutdown();
    } 

    private object DoSomeWork(object state)
    { 
        // Do the work
        return null;
    }
}</pre>

<p>The following example shows how to handle exceptions. Pay attention to the <code>Result</code> property that throws the <code>WorkItemResultException</code> and not the real exception:<a name="CatchExceptionExample"></a></p>

<pre lang="cs">public class CatchExceptionExample
{
    public void DoWork() 
    { 
        SmartThreadPool smartThreadPool = new SmartThreadPool();

        IWorkItemResult&lt;double&gt; wir = smartThreadPool.QueueWorkItem(
                  new Func&lt;double, double, double&gt;(DoDiv), 10.0, 0.0);

        try
        {
            double result = wir.Result;
        }
        // Catch the exception that Result threw
        catch (WorkItemResultException e)
        {
            // Dump the inner exception which DoDiv threw
            Debug.WriteLine(e.InnerException);
        }

        smartThreadPool.Shutdown();
    } 

    private double DoDiv(double x, double y)
    { 
        return x / y;
    }
}</pre>

<p>This is another example that shows how to handle exceptions. It is better than the previous one because it is faster. .NET works fast when everything is OK. When .NET needs to deal with exceptions, it becomes slower:<a name="GetExceptionExample"></a></p>

<pre lang="cs">public class GetExceptionExample
{
    public void DoWork() 
    { 
        SmartThreadPool smartThreadPool = new SmartThreadPool();

        IWorkItemResult&lt;double&gt; wir = smartThreadPool.QueueWorkItem(
                   new Func&lt;double, double, double&gt;(DoDiv), 10.0, 0.0);

        Exception e = null;
    double result = wir.GetResult(out e);
        // e contains the expetion that DoDiv threw
        if(null != e)
        {
            // Do something with the exception
        }

        smartThreadPool.Shutdown();
    } 

    private double DoDiv(double x, double y)
    { 
        return x / y;
    }
}</pre>

<p>The next example shows how to create a Work Items Group and use it:<a name="WorkItemsGroupExample"></a></p>

<pre lang="cs">public class WorkItemsGroupExample
{
    public void DoWork(object [] states)
    { 
        SmartThreadPool smartThreadPool = new SmartThreadPool();

        // Create a work items group that processes 
        // one work item at a time
        IWorkItemsGroup wig = 
                smartThreadPool.CreateWorkItemsGroup(1);

        // Queue some work items 
        foreach(object state in states)
        {
            wig.QueueWorkItem(
                new WorkItemCallback(this.DoSomeWork), state);
        }

        // Wait for the completion of all work 
        // items in the work items group
        wig.WaitForIdle();

        smartThreadPool.Shutdown();
    } 

    private object DoSomeWork(object state)
    { 
        // Do the work
        return null;
    }
}</pre>

<p>The next example shows how to create a suspended Smart Thread Pool:<a name="SuspendedSTPStartExample"></a></p>

<pre lang="cs">public class SuspendedSTPStartExample
{
    public void DoWork(object [] states) 
    { 
        STPStartInfo stpStartInfo = new STPStartInfo();
        stpStartInfo.StartSuspended = true;

        SmartThreadPool smartThreadPool = 
             new SmartThreadPool(stpStartInfo);

        foreach(object state in states)
        {
            smartThreadPool.QueueWorkItem(new 
                WorkItemCallback(this.DoSomeWork), state);
        }

        // Start working on the work items in the queue
        smartThreadPool.Start();

        // Wait for the completion of all work items
        smartThreadPool.WaitForIdle();

        smartThreadPool.Shutdown();
    } 

    private object DoSomeWork(object state)
    { 
        // Do the work
        return null;
    }
}</pre>

<p>The next example shows how to create a suspended Work Items Group:<a name="SuspendedWIGStartExample"></a></p>

<pre lang="cs">public class SuspendedWIGStartExample
{
    public void DoWork(object [] states) 
    { 
        SmartThreadPool smartThreadPool = new SmartThreadPool();

        WIGStartInfo wigStartInfo = new WIGStartInfo();
        wigStartInfo.StartSuspended = true;

        IWorkItemsGroup wig = 
           smartThreadPool.CreateWorkItemsGroup(1, wigStartInfo);

        foreach(object state in states)
        {
            wig.QueueWorkItem(new 
                WorkItemCallback(this.DoSomeWork), state);
        }

        // Start working on the work items 
        // in the work items group queue
        wig.Start();

        // Wait for the completion of all work items
        wig.WaitForIdle();

        smartThreadPool.Shutdown();
    } 

    private object DoSomeWork(object state)
    { 
        // Do the work
        return null;
    }
}</pre>

<p>This example shows how to get the Work Items Group's <code>OnIdle</code> event:<a name="OnWIGIdleEventExample"></a></p>

<pre lang="cs">public class OnWIGIdleEventExample
{
    public void DoWork(object [] states) 
    { 
        SmartThreadPool smartThreadPool = new SmartThreadPool();

        IWorkItemsGroup wig = 
            smartThreadPool.CreateWorkItemsGroup(1);

        wig.OnIdle += new WorkItemsGroupIdleHandler(wig_OnIdle);

        foreach(object state in states)
        {
            wig.QueueWorkItem(new 
                WorkItemCallback(this.DoSomeWork), state);
        }

        smartThreadPool.WaitForIdle();
        smartThreadPool.Shutdown();
    } 

    private object DoSomeWork(object state)
    { 
        // Do the work
        return null;
    }

    private void wig_OnIdle(IWorkItemsGroup workItemsGroup)
    {
        Debug.WriteLine(&quot;WIG is idle&quot;);
    }
}</pre>

<p>This example shows how to use <code>Join</code>:<a name="JoinExample"></a></p>

<pre lang="cs">public class JoinExample
{
    public void DoWork() 
    { 
        SmartThreadPool stp = new SmartThreadPool();

        stp.Join(DoSomeWork1, DoSomeWork2);

        smartThreadPool.Shutdown();
    } 

    private void DoSomeWork1()
    { 
        // ...
    }

    private void DoSomeWork2()
    { 
        // ...
    }
   
}</pre>

<p>This example shows how to use <code>Choice</code>:<a name="ChoiceExample"></a></p>

<pre lang="cs">public class ChoiceExample
{
    public void DoWork() 
    { 
        SmartThreadPool stp = new SmartThreadPool();

        int index = stp.Choice(GetDataFromA, GetDataFromB);

        if (index == 0)
        {
            // Got data from A
        }
        else if (index == 1)
        {
            // Got data from B
        }

        smartThreadPool.Shutdown();
    } 

    private void GetDataFromA()
    { 
        // ...
    }

    private void GetDataFromB()
    { 
        // ...
    }
   
}</pre>

<p>This example shows how to use <code>Pipe</code>:<a name="PipeExample"></a></p>

<pre lang="cs">public class PipeExample
{
    public void DoWork() 
    { 
        SmartThreadPool stp = new SmartThreadPool();
        
        int [] data = new int[2];

        stp.Pipe(data, DoStep1, DoStep2);

        smartThreadPool.Shutdown();
    } 

    private void DoStep1(int [] data)
    { 
        data[0] = ...
    }

    private void DoStep2(int [] data)
    { 
        data[1] = ...
    }
   
}</pre>

<p>This example shows how to use <code>Timeout</code>:<a name="TimeoutExample"></a></p>

<pre lang="cs">public class TimeoutExample
{
    public void DoWork() 
    { 
        SmartThreadPool stp = new SmartThreadPool();

        ...

        // Queue a work item that will be cancelled within 5 seconds
        IWorkItemResult wir = 
            stp.QueueWorkItem(
                new WorkItemInfo() { Timeout = 5*1000 }, 
                DoSomething);
        ...

        smartThreadPool.Shutdown();
    } 

    private object DoSomething(object state)
    { 
        ...

        for(...)
        {
            // If the work item was cancelled then abort the thread.
            SmartThreadPool.AbortOnWorkItemCancel();
        }
        
        ...

        return result;
    }
}</pre>

<h2>Disclaimer</h2>

<p>THIS CODE AND INFORMATION IS PROVIDED 'AS IS' WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR PURPOSE.</p>

<h2><a name="History">History</a></h2>

<ul>
<li>7<sup>th</sup> Aug, 2004: Initial version.</li>

<li>14<sup>th</sup> Sep, 2004: Bug fixes:</li>

<ol>
<li>Changed the start thread formula to '<code lang="cs">if ((InUseThreads + WaitingCallbacks) &gt; _workerThreads.Count)</code>'.</li>

<li>Fixed handle leaks.</li>
</ol>

<li>16<sup>th</sup> Oct, 2004: Added a few features:</li>

<ul>
<li>Work items return result.</li>

<li>Supports waiting synchronization for multiple work items.</li>

<li>Work items can be cancelled.</li>

<li>Passage of the caller thread's context to the thread in the pool.</li>

<li>Minimal usage of Win32 handles.</li>

<li>Minor bug fixes.</li>
</ul>

<li>26<sup>th</sup> Dec, 2004: Changes:</li>

<ul>
<li>Added <code>PostExecute</code>, with options on which cases to call it.</li>

<li>Added a <code>WaitForIdle()</code> method that waits until the work items queue is empty.</li>

<li>Added an option to dispose off the state objects.</li>

<li>Updated <code>FireUnhandledException</code> so it will be more robust.</li>

<li>Removed static constructors.</li>

<li>Added finalizers.</li>

<li>Changed exceptions so that they are serializable.</li>

<li>Fixed the bug in one of the <code>SmartThreadPool</code> constructors.</li>

<li>Changed <code>SmartThreadPool.WaitAll()</code> so that it will support any number of waiters. <code>SmartThreadPool.WaitAny()</code> is still limited by the .NET Framework.</li>

<li>Changed exception handling so if a work item throws an exception, it is re-thrown at <code>GetResult()</code>, rather than firing an <code>UnhandledException</code> event. Note that <code>PostExecute</code> exceptions are always ignored.</li>
</ul>

<li>25<sup>th</sup> Mar, 2005: Changes:</li>

<ul>
<li>Fixed a bug where the work items got lost. It happens especially when the idle timeout is small.</li>
</ul>

<li>3<sup>rd</sup> Jul, 2005: Changes:</li>

<ul>
<li>Fixed a bug where <code>Enqueue()</code> throws an exception when <code>PopWaiter()</code> returns <code lang="cs">null</code>, hardly reconstructed.</li>
</ul>

<li>16<sup>th</sup> Aug 2005: Changes:</li>

<ul>
<li>Fixed a bug where <code>InUseThreads</code> becomes negative while canceling work items.</li>
</ul>

<li>31<sup>st</sup> Jan, 2006: Changes:</li>

<ul>
<li>Added work items priority.</li>

<li>Removed support for chained delegates in callbacks and post executes (nobody really uses it).</li>

<li>Added work item groups.</li>

<li>Added work item group's idle event.</li>

<li>Changed <code>SmartThreadPool.WaitAll()</code> behavior so that when it gets an empty array, it returns <code lang="cs">true</code> rather than throwing an exception.</li>

<li>Added option to start the Smart Thread Pool and the Work Items Group as suspended.</li>

<li>Exception behavior changed (again). The real exception is returned by an inner exception.</li>

<li>Added option to keep the HTTP context of the caller thread (thanks to Steven T).</li>

<li>Added performance counters.</li>

<li>Added priority to the threads in the pool.</li>
</ul>

<li>13<sup>th</sup> Feb, 2006: Changes:</li>

<ul>
<li>Fixed the demo so that it won't crash with exception on start.</li>

<li>Added a call to dispose off the performance counters so that there is no performance counter leak.</li>

<li>Added exception catch in case the performance counters cannot be created.</li>
</ul>

<li>16<sup>th</sup> May 2008: Changes:</li>

<ul>
<li>Changed the dispose behavior and removed the finalizers.</li>

<li>Enabled the change of <code>MaxThreads</code> and <code>MinThreads</code> at run time.</li>

<li>Enabled the change of <code>Concurrency</code> of a <code>IWorkItemsGroup</code> at run time. If the <code>IWorkItemsGroup</code> is a <code>SmartThreadPool</code>, then <code>Concurrency</code> refers to <code>MaxThreads</code>.</li>

<li>Improved the Cancel behavior.</li>

<li>Added events for thread creation and termination.</li>

<li>Fixed the HttpContext context capture.</li>

<li>Changed internal collections so they use generic collections.</li>

<li>Added the IsIdle flag to the <code>SmartThreadPool</code> and <code>IWorkItemsGroup</code>.&nbsp;</li>

<li>Added support for WinCE.</li>

<li>Added support for <code>Action&lt;T&gt;</code> and <code>Func&lt;T&gt;</code>.&nbsp;</li>
</ul>

<li>7<sup>th</sup> April 2009: Changes:</li>

<ul>
<li>Added support for Silverlight and Mono.</li>

<li>Added <code>Join</code>, <code>Choice</code>, and <code>Pipe</code> to <code>SmartThreadPool</code>.</li>

<li>Added local performance counters (for Mono, Silverlight, and Windows CE).</li>

<li>Changed duration measures from <code>DateTime.Now</code> to <code>Stopwatch</code>.</li>

<li>Queues changed from <code>System.Collections.Queue</code> to <code>System.Collections.Generic.LinkedList&lt;T&gt;</code>.</li>
</ul>

<li>21<sup>st</sup> December 2009: Changes:&nbsp;</li>

<ul>
<li>Added work item timeout (passive).&nbsp;</li>
</ul>

    <li>27<sup>th</sup> August 2012: Changes</li>
        <ul>
            <li><strong>Added set name to threads</strong>&nbsp;</li>
            <li><strong>Added IsBackground option to threads</strong></li>
            <li><strong>Added ApartmentState to threads</strong></li><li><strong>Added MaxStackSize to threads</strong>&nbsp;</li>
            <li><strong>Fixed SmartThreadPool.Pipe</strong>&nbsp;</li>
            <li><strong>Fixed thread creation when queuing many work items at the same time.</strong></li>
            <li><strong>Fixed the WorkItemsQueue.Dequeue.</strong><br /><strong>
            Replaced <code>while(!Monitor.TryEnter(this));</code> with <code>lock(this) { ... }</code>&nbsp;</strong>&nbsp;</li>
        </ul>


</ul>
